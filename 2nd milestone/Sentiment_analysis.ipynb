{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c1260d-bcda-4918-ad7a-1ab1eae9f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\hospitality_ai\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\hospitality_ai\\venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: openai in d:\\hospitality_ai\\venv\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\hospitality_ai\\venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\hospitality_ai\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\hospitality_ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\hospitality_ai\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\hospitality_ai\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\hospitality_ai\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\hospitality_ai\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09161889-eb33-47db-86b6-335586661a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in d:\\hospitality_ai\\venv\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.156.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (5.29.2)\n",
      "Requirement already satisfied: pydantic in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.10.4)\n",
      "Requirement already satisfied: tqdm in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in d:\\hospitality_ai\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40388439-a9e3-4443-a593-6e2fddcab97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'review_title', 'reviewed_at', 'reviewed_by', 'images',\n",
      "       'crawled_at', 'url', 'hotel_name', 'hotel_url', 'avg_rating',\n",
      "       'nationality', 'rating', 'review_text', 'raw_review_text', 'tags',\n",
      "       'meta'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('booking_reviews copy.csv')\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b7cd41-c658-41b8-b06e-15ae24c81d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (25983, 5)\n",
      "\n",
      "Sample of cleaned dataset:\n",
      "  reviewed_by                                       review_title  \\\n",
      "0      Kyrylo                                        Exceptional   \n",
      "1     Dimitri  I highly recommend this b&b! We enjoyed it a lot!   \n",
      "2    Virginia                                        Exceptional   \n",
      "3      Kannan  My stay in the house was a experiencing bliss ...   \n",
      "4         Sue  One bedroom apartment with wonderful view and ...   \n",
      "\n",
      "               hotel_name                                        review_text  \\\n",
      "0         Villa Pura Vida  Everything was perfect! Quite, cozy place to r...   \n",
      "1         Villa Pura Vida          Very friendly host and perfect breakfast!   \n",
      "2  Hydro Palace Apartment  It was just what we wanted for a week by the b...   \n",
      "3         Villa Pura Vida  My stay in the house was a experiencing bliss ...   \n",
      "4  Hydro Palace Apartment  The building itself has a very musty smell in ...   \n",
      "\n",
      "   rating  \n",
      "0    10.0  \n",
      "1     9.0  \n",
      "2    10.0  \n",
      "3    10.0  \n",
      "4     9.2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('booking_reviews copy.csv')\n",
    "\n",
    "def clean_dataset(df):\n",
    "    cleaned_df = df[['reviewed_by', 'review_title', 'hotel_name', 'review_text', 'rating']]\n",
    "    \n",
    "    cleaned_df = cleaned_df.dropna()\n",
    "    \n",
    "    \n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "cleaned_df = clean_dataset(df)\n",
    "\n",
    "\n",
    "cleaned_df.to_csv('cleaned_hotel_reviews.csv', index=False)\n",
    "\n",
    "print(\"Dataset shape:\", cleaned_df.shape)\n",
    "print(\"\\nSample of cleaned dataset:\")\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de34a9bf-4cf2-4a41-a914-d7b714b47860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in d:\\hospitality_ai\\venv\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (0.6.10)\n",
      "Requirement already satisfied: google-api-core in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.24.0)\n",
      "Requirement already satisfied: google-api-python-client in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.156.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.37.0)\n",
      "Requirement already satisfied: protobuf in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (5.29.2)\n",
      "Requirement already satisfied: pydantic in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (2.10.4)\n",
      "Requirement already satisfied: tqdm in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in d:\\hospitality_ai\\venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.68.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\hospitality_ai\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\hospitality_ai\\venv\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9be8ad28-3fde-43b7-8e70-ebea93e298c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ce1d38-7a6f-4bc1-a4bf-ed3f5ac56a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tenacity\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity\n",
      "Successfully installed tenacity-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bde92d09-9b02-4d81-bd7e-56af6642446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from cleaned_hotel_reviews.csv...\n",
      "Total rows in original dataset: 25983\n",
      "Reducing to 10 rows...\n",
      "Reduced dataset saved to reduced_hotel_reviews.csv\n",
      "New dataset size: 10 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reduce_dataset(input_file, output_file, sample_size):\n",
    "    print(f\"Reading from {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    print(f\"Total rows in original dataset: {len(df)}\")\n",
    "    \n",
    "    if sample_size >= len(df):\n",
    "        print(\"Sample size is larger than or equal to the dataset size. No reduction needed.\")\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"Original dataset saved to {output_file}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Reducing to {sample_size} rows...\")\n",
    "    \n",
    "    # Randomly sample the data\n",
    "    sampled_df = df.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Write the sampled data to a new CSV file\n",
    "    sampled_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Reduced dataset saved to {output_file}\")\n",
    "    print(f\"New dataset size: {len(sampled_df)} rows\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = 'cleaned_hotel_reviews.csv'\n",
    "    output_file = 'reduced_hotel_reviews.csv'\n",
    "    sample_size = 10 \n",
    "    \n",
    "    reduce_dataset(input_file, output_file, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a6cd8-a314-42e3-927c-1a48cef6333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new analysis...\n",
      "\n",
      "Processing batch 1 (0-5 of 10)\n",
      "Processed review 0 - Sentiment: neutral, Score: 0.90\n",
      "Processed review 1 - Sentiment: positive, Score: 0.98\n",
      "Processed review 2 - Sentiment: negative, Score: 0.60\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Processed review 3 - Sentiment: neutral, Score: 0.90\n",
      "Processed review 4 - Sentiment: positive, Score: 0.90\n",
      "Progress saved at review 5\n",
      "\n",
      "Processing batch 2 (5-10 of 10)\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Processed review 5 - Sentiment: negative, Score: 0.80\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Processed review 6 - Sentiment: positive, Score: 0.85\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Processed review 7 - Sentiment: positive, Score: 0.99\n",
      "Processed review 8 - Sentiment: negative, Score: 0.95\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Error analyzing sentiment for text: 'NoneType' object is not subscriptable\n",
      "Processed review 9 - Sentiment: neutral, Score: 1.00\n",
      "Progress saved at review 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenRouter client\n",
    "openai = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv('OPENROUTER_API_KEY')\n",
    ")\n",
    "\n",
    "@retry(\n",
    "    wait=wait_exponential(multiplier=1, min=4, max=60),  # Wait between retries, increasing exponentially\n",
    "    stop=stop_after_attempt(5)  # Stop after 5 attempts\n",
    ")\n",
    "def analyze_sentiment(text: str) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of a given text using OpenRouter API with Gemini model.\n",
    "    Returns a tuple of (sentiment_label, confidence_score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Add delay between requests to respect rate limits\n",
    "        time.sleep(10)  \n",
    "        \n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"google/gemini-2.0-flash-exp:free\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a sentiment analysis expert. Analyze the sentiment of the given text and respond with only two values: sentiment_label (positive, negative, or neutral) and confidence_score (between 0 and 1) separated by a comma.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Parse the response\n",
    "        response = completion.choices[0].message.content\n",
    "        sentiment_label, confidence_score = response.strip().split(',')\n",
    "        confidence_score = float(confidence_score)\n",
    "        \n",
    "        return sentiment_label, confidence_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing sentiment for text: {e}\")\n",
    "        raise  \n",
    "\n",
    "def process_in_batches(df: pd.DataFrame, batch_size: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the dataframe in batches and save progress periodically\n",
    "    \"\"\"\n",
    "    df['sentiment_label'] = ''\n",
    "    df['sentiment_score'] = 0.0\n",
    "    \n",
    "    total_reviews = len(df)\n",
    "    \n",
    "    for start_idx in range(0, total_reviews, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_reviews)\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"\\nProcessing batch {start_idx//batch_size + 1} ({start_idx}-{end_idx} of {total_reviews})\")\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                label, score = analyze_sentiment(row['review_text'])\n",
    "                df.at[idx, 'sentiment_label'] = label\n",
    "                df.at[idx, 'sentiment_score'] = score\n",
    "                print(f\"Processed review {idx} - Sentiment: {label}, Score: {score:.2f}\")\n",
    "                \n",
    "                # Save progress after each batch\n",
    "                if (idx + 1) % batch_size == 0:\n",
    "                    df.to_csv('sentiment_analysis_progress.csv', index=False)\n",
    "                    print(f\"Progress saved at review {idx + 1}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process review {idx}: {e}\")\n",
    "                # Save progress before exiting\n",
    "                df.to_csv('sentiment_analysis_progress.csv', index=False)\n",
    "                print(\"Progress saved due to error\")\n",
    "                continue\n",
    "        \n",
    "        time.sleep(500)  # 5 second delay between batches\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Check if there's a progress file\n",
    "        if os.path.exists('sentiment_analysis_progress.csv'):\n",
    "            print(\"Found existing progress file. Resuming from last saved state...\")\n",
    "            df_with_sentiment = pd.read_csv('sentiment_analysis_progress.csv')\n",
    "            # Filter out reviews that haven't been processed yet\n",
    "            remaining_reviews = df_with_sentiment[df_with_sentiment['sentiment_label'] == '']\n",
    "            if len(remaining_reviews) > 0:\n",
    "                print(f\"Continuing with {len(remaining_reviews)} remaining reviews...\")\n",
    "                df_with_sentiment = process_in_batches(remaining_reviews, batch_size=5)\n",
    "            else:\n",
    "                print(\"All reviews have been processed!\")\n",
    "        else:\n",
    "            # Load the cleaned dataset\n",
    "            print(\"Starting new analysis...\")\n",
    "            df_with_sentiment = pd.read_csv('reduced_hotel_reviews.csv')\n",
    "            df_with_sentiment = process_in_batches(df_with_sentiment, batch_size=5)\n",
    "        \n",
    "        # Save final results\n",
    "        output_file = 'hotel_reviews_with_sentiment_openrouter.csv'\n",
    "        df_with_sentiment.to_csv(output_file, index=False)\n",
    "        print(f\"\\nFinal results saved to {output_file}\")\n",
    "        \n",
    "        # Display sample results\n",
    "        print(\"\\nSample results with sentiment analysis:\")\n",
    "        print(df_with_sentiment[['review_text', 'sentiment_label', 'sentiment_score']].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f3ee2f-492d-4c86-b05b-617deef57d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp)\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: idna>=2.0 in d:\\hospitality_ai\\venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp) (3.10)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: propcache, multidict, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, aiohttp\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 attrs-24.3.0 frozenlist-1.5.0 multidict-6.1.0 propcache-0.2.1 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install aiohttp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6893f211-362f-4069-9190-93543a76a008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\": \"Loading the dataset from cleaned_hotel_reviews.csv...\"}\n",
      "{\"status\": \"Dataset loaded successfully\", \"rows\": 25983}\n",
      "{\"status\": \"Real-time sentiment analysis system is ready!\"}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a hotel review (or 'quit' to exit):  The room and bathroom were tiny but clean and modern. The fisrt room that we were offered was in the basement without natural light, humidity and small. After our disappointment, the manager change us to a room in the 2on floor with a better light and maybe bigger. ,  The hotel is clean and new. The bathroom was really comfortable and super clean. Also the location is perfect, very near to many restaurants.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"warning\": \"Attempt 1 failed. Retrying...\"}\n",
      "{\"warning\": \"Attempt 2 failed. Retrying...\"}\n",
      "{\"error\": \"Error in sentiment analysis: Expecting value: line 1 column 1 (char 0)\"}\n",
      "{\n",
      "  \"review\": \"The room and bathroom were tiny but clean and modern. The fisrt room that we were offered was in the basement without natural light, humidity and small. After our disappointment, the manager change us to a room in the 2on floor with a better light and maybe bigger. ,  The hotel is clean and new. The bathroom was really comfortable and super clean. Also the location is perfect, very near to many restaurants.\",\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 0.5,\n",
      "  \"alerts\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a hotel review (or 'quit' to exit):  quit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OpenRouter API setup\n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    prompt = f\"\"\"Analyze the sentiment of the following hotel review. Respond with a JSON object containing two keys: \n",
    "    \"sentiment\" (with values \"positive\", \"negative\", or \"neutral\") and \"confidence\" (a float between 0 and 1).\n",
    "\n",
    "    Review: \"{text}\"\n",
    "\n",
    "    Respond only with the JSON object, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"google/gemini-2.0-flash-exp:free\",  \n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert for hotel reviews. Always respond with valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            sentiment_data = json.loads(result['choices'][0]['message']['content'])\n",
    "            return sentiment_data\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(json.dumps({\"error\": f\"Error in sentiment analysis: {str(e)}\"}))\n",
    "                return {\"sentiment\": \"neutral\", \"confidence\": 0.5}\n",
    "            else:\n",
    "                print(json.dumps({\"warning\": f\"Attempt {attempt + 1} failed. Retrying...\"}))\n",
    "                time.sleep(2 ** attempt)  \n",
    "\n",
    "def generate_alerts(text, sentiment, confidence):\n",
    "    departments = {\n",
    "        'cleanliness': ['clean', 'dirty', 'hygiene', 'housekeeping'],\n",
    "        'service': ['staff', 'service', 'reception', 'concierge'],\n",
    "        'amenities': ['pool', 'gym', 'spa', 'restaurant', 'breakfast'],\n",
    "        'maintenance': ['broken', 'malfunction', 'repair', 'fix']\n",
    "    }\n",
    "    \n",
    "    alerts = []\n",
    "    if sentiment == 'negative' and confidence > 0.7:\n",
    "        for dept, keywords in departments.items():\n",
    "            if any(keyword in text.lower() for keyword in keywords):\n",
    "                alerts.append(f\"ALERT: Negative feedback for {dept.capitalize()} department\")\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "def main():\n",
    "    local_file_path = 'cleaned_hotel_reviews.csv'  \n",
    "    print(json.dumps({\"status\": f\"Loading the dataset from {local_file_path}...\"}))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(local_file_path)\n",
    "        print(json.dumps({\"status\": \"Dataset loaded successfully\", \"rows\": len(df)}))\n",
    "    except FileNotFoundError:\n",
    "        print(json.dumps({\"error\": f\"File not found: {local_file_path}\"}))\n",
    "        return\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(json.dumps({\"error\": \"The file is empty\"}))\n",
    "        return\n",
    "    except pd.errors.ParserError:\n",
    "        print(json.dumps({\"error\": \"Error parsing the CSV file\"}))\n",
    "        return\n",
    "    \n",
    "    print(json.dumps({\"status\": \"Real-time sentiment analysis system is ready!\"}))\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter a hotel review (or 'quit' to exit): \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        sentiment_data = analyze_sentiment(user_input)\n",
    "        alerts = generate_alerts(user_input, sentiment_data['sentiment'], sentiment_data['confidence'])\n",
    "        \n",
    "        output = {\n",
    "            \"review\": user_input,\n",
    "            \"sentiment\": sentiment_data['sentiment'],\n",
    "            \"confidence\": sentiment_data['confidence'],\n",
    "            \"alerts\": alerts\n",
    "        }\n",
    "        \n",
    "        print(json.dumps(output, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99ebc58-ab3b-4e63-a475-dbe10ea0ff43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\": \"Loading the dataset from cleaned_hotel_reviews.csv...\"}\n",
      "{\"status\": \"Dataset loaded successfully\", \"rows\": 25983}\n",
      "{\"status\": \"Real-time sentiment analysis system is ready!\"}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'a' to analyze a random review from the dataset, 'n' for a new review, or 'quit' to exit:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"info\": \"Analyzing random review: 'The flat was old and not in a good condition. The ...' (Rating: 3.8)\"}\n",
      "{\"warning\": \"Attempt 1 failed. Retrying...\"}\n",
      "{\"warning\": \"Attempt 2 failed. Retrying...\"}\n",
      "{\"error\": \"Error in sentiment analysis: Expecting value: line 1 column 1 (char 0)\"}\n",
      "{\n",
      "  \"review\": \"The flat was old and not in a good condition. The window was broken and the heater did not work as expected. The lamp in the bathroom was broken.\",\n",
      "  \"rating\": 3.8,\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 0.5,\n",
      "  \"analysis\": \"Error occurred during analysis\",\n",
      "  \"alerts\": [\n",
      "    \"ALERT: Negative feedback for Maintenance department\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'a' to analyze a random review from the dataset, 'n' for a new review, or 'quit' to exit:  n\n",
      "Enter the review text:  The room and bathroom were tiny but clean and modern. The fisrt room that we were offered was in the basement without natural light, humidity and small. After our disappointment, the manager change us to a room in the 2on floor with a better light and maybe bigger. ,  The hotel is clean and new. The bathroom was really comfortable and super clean. Also the location is perfect, very near to many restaurants.\n",
      "Enter the rating (0-10):  7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"warning\": \"Attempt 1 failed. Retrying...\"}\n",
      "{\"warning\": \"Attempt 2 failed. Retrying...\"}\n",
      "{\"error\": \"Error in sentiment analysis: Expecting value: line 1 column 1 (char 0)\"}\n",
      "{\n",
      "  \"review\": \"The room and bathroom were tiny but clean and modern. The fisrt room that we were offered was in the basement without natural light, humidity and small. After our disappointment, the manager change us to a room in the 2on floor with a better light and maybe bigger. ,  The hotel is clean and new. The bathroom was really comfortable and super clean. Also the location is perfect, very near to many restaurants.\",\n",
      "  \"rating\": \"7.5\",\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"confidence\": 0.5,\n",
      "  \"analysis\": \"Error occurred during analysis\",\n",
      "  \"alerts\": []\n",
      "}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter 'a' to analyze a random review from the dataset, 'n' for a new review, or 'quit' to exit:  quit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OpenRouter API setup\n",
    "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "OPENROUTER_API_URL = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "def analyze_sentiment(text, rating):\n",
    "    prompt = f\"\"\"Analyze the sentiment of the following hotel review, considering both the text and the numerical rating. \n",
    "    Respond with a JSON object containing three keys: \n",
    "    \"sentiment\" (with values \"positive\", \"negative\", or \"neutral\"),\n",
    "    \"confidence\" (a float between 0 and 1), and\n",
    "    \"analysis\" (a brief explanation of how the text and rating influenced the sentiment decision).\n",
    "\n",
    "    Review: \"{text}\"\n",
    "    Rating: {rating} (on a scale of 0 to 10)\n",
    "\n",
    "    Respond only with the JSON object, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"google/gemini-2.0-flash-exp:free\",  \n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis expert for hotel reviews. Always respond with valid JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(OPENROUTER_API_URL, headers=headers, json=data)\n",
    "            response.raise_for_status()\n",
    "            result = response.json()\n",
    "            sentiment_data = json.loads(result['choices'][0]['message']['content'])\n",
    "            return sentiment_data\n",
    "        except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(json.dumps({\"error\": f\"Error in sentiment analysis: {str(e)}\"}))\n",
    "                return {\"sentiment\": \"neutral\", \"confidence\": 0.5, \"analysis\": \"Error occurred during analysis\"}\n",
    "            else:\n",
    "                print(json.dumps({\"warning\": f\"Attempt {attempt + 1} failed. Retrying...\"}))\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "\n",
    "def generate_alerts(text, sentiment, confidence, rating):\n",
    "    departments = {\n",
    "        'cleanliness': ['clean', 'dirty', 'hygiene', 'housekeeping'],\n",
    "        'service': ['staff', 'service', 'reception', 'concierge'],\n",
    "        'amenities': ['pool', 'gym', 'spa', 'restaurant', 'breakfast'],\n",
    "        'maintenance': ['broken', 'malfunction', 'repair', 'fix']\n",
    "    }\n",
    "    \n",
    "    alerts = []\n",
    "    if (sentiment == 'negative' and confidence > 0.7) or float(rating) < 5.0:\n",
    "        for dept, keywords in departments.items():\n",
    "            if any(keyword in text.lower() for keyword in keywords):\n",
    "                alerts.append(f\"ALERT: Negative feedback for {dept.capitalize()} department\")\n",
    "        \n",
    "        if not alerts:\n",
    "            alerts.append(\"ALERT: General negative feedback detected\")\n",
    "    \n",
    "    return alerts\n",
    "\n",
    "def main():\n",
    "    local_file_path = 'cleaned_hotel_reviews.csv'  # Update this to your local file path\n",
    "    print(json.dumps({\"status\": f\"Loading the dataset from {local_file_path}...\"}))\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(local_file_path)\n",
    "        print(json.dumps({\"status\": \"Dataset loaded successfully\", \"rows\": len(df)}))\n",
    "    except FileNotFoundError:\n",
    "        print(json.dumps({\"error\": f\"File not found: {local_file_path}\"}))\n",
    "        return\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(json.dumps({\"error\": \"The file is empty\"}))\n",
    "        return\n",
    "    except pd.errors.ParserError:\n",
    "        print(json.dumps({\"error\": \"Error parsing the CSV file\"}))\n",
    "        return\n",
    "    \n",
    "    print(json.dumps({\"status\": \"Real-time sentiment analysis system is ready!\"}))\n",
    "    while True:\n",
    "        user_input = input(\"\\nEnter 'a' to analyze a random review from the dataset, 'n' for a new review, or 'quit' to exit: \")\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        elif user_input.lower() == 'a':\n",
    "            # Select a random review from the dataset\n",
    "            random_review = df.sample(n=1).iloc[0]\n",
    "            review_text = random_review['review_text']\n",
    "            rating = random_review['rating']\n",
    "            print(json.dumps({\"info\": f\"Analyzing random review: '{review_text[:50]}...' (Rating: {rating})\"}))\n",
    "        elif user_input.lower() == 'n':\n",
    "            review_text = input(\"Enter the review text: \")\n",
    "            rating = input(\"Enter the rating (0-10): \")\n",
    "        else:\n",
    "            print(json.dumps({\"error\": \"Invalid input. Please enter 'a', 'n', or 'quit'.\"}))\n",
    "            continue\n",
    "        \n",
    "        sentiment_data = analyze_sentiment(review_text, rating)\n",
    "        alerts = generate_alerts(review_text, sentiment_data['sentiment'], sentiment_data['confidence'], rating)\n",
    "        \n",
    "        output = {\n",
    "            \"review\": review_text,\n",
    "            \"rating\": rating,\n",
    "            \"sentiment\": sentiment_data['sentiment'],\n",
    "            \"confidence\": sentiment_data['confidence'],\n",
    "            \"analysis\": sentiment_data['analysis'],\n",
    "            \"alerts\": alerts\n",
    "        }\n",
    "        \n",
    "        print(json.dumps(output, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
